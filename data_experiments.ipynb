{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f20d1d",
   "metadata": {},
   "source": [
    "# Data Pooling Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03babab",
   "metadata": {},
   "source": [
    "Where we analyze and present the results described in Section 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc2000",
   "metadata": {},
   "source": [
    "1. [Preeliminaries](#Preeliminaries)\n",
    "2. [Natural Partitions](#Natural-Partitions)\n",
    "    - [Table 3.2](#Natural-Partitions)\n",
    "    \n",
    "    \n",
    "3. [Synthetic Partitions](#Synthetic-Partitions)\n",
    "    - [Table 3.3 Summary](#Synthetic-Partitions)\n",
    "    - [Table 3.4 By Params](#Group-by-partition-parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f3e38",
   "metadata": {},
   "source": [
    "## Preeliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68059f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import inspect,sys\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datasets,utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4ab754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_index(df):\n",
    "    return min([(i,len(i.split(\",\"))) for i in df.index],key=lambda x:x[1])[0]\n",
    "\n",
    "def global_index(df):\n",
    "    return max([(i,len(i.split(','))) for i in df.index],key=lambda x:x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a33614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n(partition,subset):\n",
    "    #islands=[i.split(\"'\")[1] for i in subset.split(',')]\n",
    "    return sum(len(partition[island][1]) for island in get_islands_from_str(subset))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c004345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_islands_from_str(s):\n",
    "    tmp=[i.strip() for i in s.replace('(','').replace(')','').replace('\\'','').split(',') if i.strip()]\n",
    "    if '\\'' not in s:\n",
    "        tmp=[int(i) for i in tmp]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d77dcad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_0s(partition,subset,exclude=''):\n",
    "    islands=[i for i in get_islands_from_str(subset) if i!=exclude]\n",
    "    zero=sorted(partition[islands[0]][1].unique())[0]\n",
    "    n=get_n(partition,subset)\n",
    "    return sum((partition[island][1]==zero).sum() for island in islands)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee543d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR='results/data_experiments'\n",
    "PARTITIONS_DIR='partitions/data_experiments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5cf9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics={\n",
    "        'regression':['r2','neg_mean_squared_error'],\n",
    "        'classification':['balanced_accuracy','accuracy'] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ac27451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_table(results_info):\n",
    "    # We then construct the table\n",
    "    rows=[]\n",
    "    \n",
    "    negative_scores=0\n",
    "    \n",
    "    perf_by_n={}\n",
    "\n",
    "    for partition_name,(results_file,partition_file) in results_info.items():\n",
    "\n",
    "        partition_info=utils.loadPickeObj(partition_file)\n",
    "        results_by_island=utils.loadPickeObj(results_file)\n",
    "        partition,dataset=partition_info['partition'],partition_info['dataset']()\n",
    "        \n",
    "        perf_by_n[partition_name]={island:[] for island in results_by_island}\n",
    "\n",
    "        for island,results_df in results_by_island.items():\n",
    "\n",
    "            tmp=results_df['test_'+metrics[dataset.task][0]].round(2)\n",
    "            negative_scores+=(tmp<0).sum()\n",
    "\n",
    "            # Scores\n",
    "            local_score=tmp[local_index(tmp)]\n",
    "            global_score=tmp[global_index(tmp)]\n",
    "            max_score=tmp.max()\n",
    "            min_score=tmp.min()\n",
    "            runner_score=tmp.sort_values(ascending=False)[1]\n",
    "            best_subset=tmp.index[tmp.argmax()]\n",
    "            worst_subset=tmp.index[tmp.argmin()]\n",
    "\n",
    "            # N\n",
    "            total_n=get_n(partition,global_index(tmp))\n",
    "            prop_n_local=get_n(partition,local_index(tmp))/total_n\n",
    "            prop_n_best=get_n(partition,best_subset)/total_n\n",
    "            prop_n_worst=get_n(partition,worst_subset)/total_n\n",
    "\n",
    "            # 0s\n",
    "            prop_0s_local=np.nan\n",
    "            prop_0s_global=np.nan\n",
    "            prop_0s_best=np.nan\n",
    "            prop_0s_worst=np.nan\n",
    "            \n",
    "            if dataset.task=='classification':\n",
    "                prop_0s_local=get_0s(partition,local_index(tmp))\n",
    "                prop_0s_global=get_0s(partition,global_index(tmp))\n",
    "                prop_0s_best=get_0s(partition,best_subset)#exclude=local_index(tmp))\n",
    "                prop_0s_worst=get_0s(partition,worst_subset) #,exclude=local_index(tmp))\n",
    "\n",
    "            best_subset_text='Global'\n",
    "            if best_subset==local_index(tmp):\n",
    "                best_subset_text='Local'\n",
    "            elif best_subset!=global_index(tmp):\n",
    "                best_subset_text=set(get_islands_from_str(best_subset))\n",
    "\n",
    "            worst_subset_text='Global'\n",
    "            if worst_subset==local_index(tmp):\n",
    "                worst_subset_text='Local'\n",
    "            elif worst_subset!=global_index(tmp):\n",
    "                worst_subset_text=set(get_islands_from_str(worst_subset))\n",
    "\n",
    "            rows.append([\n",
    "                partition_name,\n",
    "                dataset.task,\n",
    "                island,best_subset_text,worst_subset_text,\n",
    "                max_score-local_score,\n",
    "                max_score-global_score,\n",
    "                100*prop_n_local,\n",
    "                100*prop_n_best,\n",
    "                100*prop_n_worst,\n",
    "                100*len(get_islands_from_str(best_subset))/len(get_islands_from_str(global_index(tmp))),\n",
    "                prop_0s_local,\n",
    "                prop_0s_global,\n",
    "                prop_0s_best,\n",
    "                prop_0s_worst,\n",
    "            ])\n",
    "            \n",
    "            local_n=get_n(partition,local_index(tmp))\n",
    "            if max_score!=min_score:\n",
    "                for island_set in tmp.index:\n",
    "                    prop_n=get_n(partition,island_set)/total_n #(get_n(partition,island_set)-local_n)/(total_n-local_n)\n",
    "                    prop_perf=tmp[island_set]/max_score #(tmp[island_set]-min_score)/(max_score-min_score)\n",
    "                    perf_by_n[partition_name][island].append((prop_n,prop_perf))\n",
    "            \n",
    "    if negative_scores>0:\n",
    "        print(f'Found {negative_scores} negative scores!')\n",
    "\n",
    "    return (pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[\n",
    "            'Partition','Task','Island','Best Model','Worst Model','Local Delta',\n",
    "            'Global Delta','Size of Local (%)',\"Best's dataset size (%)\",\n",
    "            'Size of Worst (%)',\"Best's set size (%)\",'Prop 0s local','Prop 0s global','Prop 0s best','Prop 0s worst',\n",
    "        ]\n",
    "    ).sort_values(['Partition','Island']),\n",
    "    perf_by_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9910c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results and the corresponding partition file\n",
    "\n",
    "# ID string -> (result file, partition file)\n",
    "results_info={}\n",
    "\n",
    "for fname in os.listdir(RESULTS_DIR):\n",
    "    if '.pkl' not in fname: continue\n",
    "    id_str=fname.replace('.pkl','')\n",
    "\n",
    "    # Check that partition file exists\n",
    "    if fname not in os.listdir(PARTITIONS_DIR):\n",
    "        print(f'Partition file not found for {id_str} in {PARTITIONS_DIR}. Skipping.')\n",
    "        continue\n",
    "    \n",
    "    # Save \n",
    "    results_file=os.path.join(RESULTS_DIR,fname)\n",
    "    partition_file=os.path.join(PARTITIONS_DIR,fname)\n",
    "    results_info[id_str]=(results_file,partition_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03a010a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory we will save graphs and tables to\n",
    "os.makedirs('tmp/data_experiments',exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73511e6",
   "metadata": {},
   "source": [
    "## Natural Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fdbb62b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Filter out non natural partitions\n",
    "natural_results_info={k:v for k,v in results_info.items() if 'natural' in k}\n",
    "\n",
    "# Construct the table (as a DataFrame)\n",
    "natural_table,perf_by_n_natural=construct_table(natural_results_info)\n",
    "\n",
    "# Remove quotes from Best Model col\n",
    "natural_table['Best Model']=natural_table['Best Model'].astype('str').str.replace(\"'\",\"\")\n",
    "\n",
    "# Save it as a csv - Table 3.2.\n",
    "natural_table.to_csv('tmp/data_experiments/natural_table.csv',index=False)\n",
    "\n",
    "# Display it\n",
    "#natural_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a92857c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Delta</th>\n",
       "      <th>Global Delta</th>\n",
       "      <th>Size of Local (%)</th>\n",
       "      <th>Best's dataset size (%)</th>\n",
       "      <th>Size of Worst (%)</th>\n",
       "      <th>Best's set size (%)</th>\n",
       "      <th>Prop 0s local</th>\n",
       "      <th>Prop 0s global</th>\n",
       "      <th>Prop 0s best</th>\n",
       "      <th>Prop 0s worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.092727</td>\n",
       "      <td>0.020606</td>\n",
       "      <td>15.151515</td>\n",
       "      <td>48.826846</td>\n",
       "      <td>29.812599</td>\n",
       "      <td>44.023569</td>\n",
       "      <td>0.786124</td>\n",
       "      <td>0.782073</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.807119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.018865</td>\n",
       "      <td>17.456680</td>\n",
       "      <td>22.399718</td>\n",
       "      <td>25.782817</td>\n",
       "      <td>18.229943</td>\n",
       "      <td>0.062371</td>\n",
       "      <td>0.011169</td>\n",
       "      <td>0.022901</td>\n",
       "      <td>0.044437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.897698</td>\n",
       "      <td>6.335292</td>\n",
       "      <td>4.437594</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.697124</td>\n",
       "      <td>0.760492</td>\n",
       "      <td>0.754165</td>\n",
       "      <td>0.741385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>6.748351</td>\n",
       "      <td>32.313520</td>\n",
       "      <td>15.346977</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.736733</td>\n",
       "      <td>0.787468</td>\n",
       "      <td>0.771309</td>\n",
       "      <td>0.779736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>9.217667</td>\n",
       "      <td>52.102989</td>\n",
       "      <td>17.808091</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>0.780289</td>\n",
       "      <td>0.787468</td>\n",
       "      <td>0.779654</td>\n",
       "      <td>0.811749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>14.366007</td>\n",
       "      <td>63.420514</td>\n",
       "      <td>32.360234</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>0.821536</td>\n",
       "      <td>0.787468</td>\n",
       "      <td>0.780736</td>\n",
       "      <td>0.824808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>93.664708</td>\n",
       "      <td>98.102302</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.921129</td>\n",
       "      <td>0.787468</td>\n",
       "      <td>0.854029</td>\n",
       "      <td>0.921129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Local Delta  Global Delta  Size of Local (%)  Best's dataset size (%)  \\\n",
       "count    33.000000     33.000000          33.000000                33.000000   \n",
       "mean      0.092727      0.020606          15.151515                48.826846   \n",
       "std       0.081481      0.018865          17.456680                22.399718   \n",
       "min       0.000000      0.000000           1.897698                 6.335292   \n",
       "25%       0.020000      0.010000           6.748351                32.313520   \n",
       "50%       0.080000      0.010000           9.217667                52.102989   \n",
       "75%       0.130000      0.030000          14.366007                63.420514   \n",
       "max       0.260000      0.070000          93.664708                98.102302   \n",
       "\n",
       "       Size of Worst (%)  Best's set size (%)  Prop 0s local  Prop 0s global  \\\n",
       "count          33.000000            33.000000      15.000000       15.000000   \n",
       "mean           29.812599            44.023569       0.786124        0.782073   \n",
       "std            25.782817            18.229943       0.062371        0.011169   \n",
       "min             4.437594            16.666667       0.697124        0.760492   \n",
       "25%            15.346977            33.333333       0.736733        0.787468   \n",
       "50%            17.808091            44.444444       0.780289        0.787468   \n",
       "75%            32.360234            58.333333       0.821536        0.787468   \n",
       "max           100.000000            75.000000       0.921129        0.787468   \n",
       "\n",
       "       Prop 0s best  Prop 0s worst  \n",
       "count     15.000000      15.000000  \n",
       "mean       0.781852       0.807119  \n",
       "std        0.022901       0.044437  \n",
       "min        0.754165       0.741385  \n",
       "25%        0.771309       0.779736  \n",
       "50%        0.779654       0.811749  \n",
       "75%        0.780736       0.824808  \n",
       "max        0.854029       0.921129  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics for every numeric column\n",
    "natural_table.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e045f53",
   "metadata": {},
   "source": [
    "## Synthetic Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d237dd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Island</th>\n",
       "      <th>Local Delta</th>\n",
       "      <th>Global Delta</th>\n",
       "      <th>Size of Local (%)</th>\n",
       "      <th>Best's dataset size (%)</th>\n",
       "      <th>Size of Worst (%)</th>\n",
       "      <th>Best's set size (%)</th>\n",
       "      <th>Prop 0s local</th>\n",
       "      <th>Prop 0s global</th>\n",
       "      <th>Prop 0s best</th>\n",
       "      <th>Prop 0s worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1125.000000</td>\n",
       "      <td>1125.000000</td>\n",
       "      <td>1125.000000</td>\n",
       "      <td>1125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.058417</td>\n",
       "      <td>0.013531</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>71.154791</td>\n",
       "      <td>25.558977</td>\n",
       "      <td>60.617143</td>\n",
       "      <td>0.565811</td>\n",
       "      <td>0.565792</td>\n",
       "      <td>0.564796</td>\n",
       "      <td>0.566099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.414618</td>\n",
       "      <td>0.051615</td>\n",
       "      <td>0.037775</td>\n",
       "      <td>16.058105</td>\n",
       "      <td>23.788675</td>\n",
       "      <td>20.676113</td>\n",
       "      <td>24.367745</td>\n",
       "      <td>0.251265</td>\n",
       "      <td>0.183382</td>\n",
       "      <td>0.205023</td>\n",
       "      <td>0.225389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.064009</td>\n",
       "      <td>2.256742</td>\n",
       "      <td>2.111405</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.144515</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.068400</td>\n",
       "      <td>59.933912</td>\n",
       "      <td>12.599938</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.356495</td>\n",
       "      <td>0.427836</td>\n",
       "      <td>0.426906</td>\n",
       "      <td>0.414251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.986804</td>\n",
       "      <td>79.553622</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.598654</td>\n",
       "      <td>0.536224</td>\n",
       "      <td>0.525213</td>\n",
       "      <td>0.577806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>89.490179</td>\n",
       "      <td>33.229056</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.780036</td>\n",
       "      <td>0.759206</td>\n",
       "      <td>0.777334</td>\n",
       "      <td>0.777090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>85.500031</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.999362</td>\n",
       "      <td>0.852423</td>\n",
       "      <td>0.999362</td>\n",
       "      <td>0.997055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Island  Local Delta  Global Delta  Size of Local (%)  \\\n",
       "count  1750.000000  1750.000000   1750.000000        1750.000000   \n",
       "mean      2.000000     0.058417      0.013531          20.000000   \n",
       "std       1.414618     0.051615      0.037775          16.058105   \n",
       "min       0.000000     0.000000      0.000000           2.064009   \n",
       "25%       1.000000     0.020000      0.000000          12.068400   \n",
       "50%       2.000000     0.040000      0.000000          19.986804   \n",
       "75%       3.000000     0.090000      0.010000          20.000000   \n",
       "max       4.000000     0.340000      0.280000          85.500031   \n",
       "\n",
       "       Best's dataset size (%)  Size of Worst (%)  Best's set size (%)  \\\n",
       "count              1750.000000        1750.000000          1750.000000   \n",
       "mean                 71.154791          25.558977            60.617143   \n",
       "std                  23.788675          20.676113            24.367745   \n",
       "min                   2.256742           2.111405            20.000000   \n",
       "25%                  59.933912          12.599938            40.000000   \n",
       "50%                  79.553622          20.000000            60.000000   \n",
       "75%                  89.490179          33.229056            80.000000   \n",
       "max                 100.000000         100.000000           100.000000   \n",
       "\n",
       "       Prop 0s local  Prop 0s global  Prop 0s best  Prop 0s worst  \n",
       "count    1125.000000     1125.000000   1125.000000    1125.000000  \n",
       "mean        0.565811        0.565792      0.564796       0.566099  \n",
       "std         0.251265        0.183382      0.205023       0.225389  \n",
       "min         0.000236        0.144515      0.002210       0.000754  \n",
       "25%         0.356495        0.427836      0.426906       0.414251  \n",
       "50%         0.598654        0.536224      0.525213       0.577806  \n",
       "75%         0.780036        0.759206      0.777334       0.777090  \n",
       "max         0.999362        0.852423      0.999362       0.997055  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out natural partitions\n",
    "synth_results_info={k:v for k,v in results_info.items() if 'natural' not in k}\n",
    "\n",
    "# Construct the table (as a DataFrame)\n",
    "synth_table,perf_by_n_synth=construct_table(synth_results_info)\n",
    "\n",
    "# Save it as a csv\n",
    "synth_table.to_csv('tmp/data_experiments_synth_table.csv',index=False)\n",
    "\n",
    "# Construct extra columns\n",
    "synth_table[['Data','P. Method','Param','Clients','Run ID']]=synth_table['Partition'].str.split(pat='_',expand=True)\n",
    "synth_table['Param']=synth_table['Param'].str.split(pat='=',expand=True)[1]\n",
    "\n",
    "# Summary statistics for every numeric column - Table 3.3\n",
    "synth_table.describe().to_csv('tmp/data_experiments/synth_summary.csv')\n",
    "synth_table.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29a73f",
   "metadata": {},
   "source": [
    "## Group by partition parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7c5665d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Local Delta</th>\n",
       "      <th>Global Delta</th>\n",
       "      <th>Best's set size (%)</th>\n",
       "      <th>Best's dataset size (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P. Method</th>\n",
       "      <th>Param</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dirY</th>\n",
       "      <th>0.5</th>\n",
       "      <td>0.07976</td>\n",
       "      <td>0.06544</td>\n",
       "      <td>52.32</td>\n",
       "      <td>52.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.09080</td>\n",
       "      <td>0.05448</td>\n",
       "      <td>59.84</td>\n",
       "      <td>59.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.09776</td>\n",
       "      <td>0.04824</td>\n",
       "      <td>54.88</td>\n",
       "      <td>54.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.10888</td>\n",
       "      <td>0.00472</td>\n",
       "      <td>79.20</td>\n",
       "      <td>79.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">powN</th>\n",
       "      <th>0.1</th>\n",
       "      <td>0.06560</td>\n",
       "      <td>0.00316</td>\n",
       "      <td>46.48</td>\n",
       "      <td>84.210697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.04836</td>\n",
       "      <td>0.00144</td>\n",
       "      <td>57.44</td>\n",
       "      <td>80.066621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.03844</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>64.32</td>\n",
       "      <td>75.347766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.03460</td>\n",
       "      <td>0.00160</td>\n",
       "      <td>67.52</td>\n",
       "      <td>69.877587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03332</td>\n",
       "      <td>0.00108</td>\n",
       "      <td>65.44</td>\n",
       "      <td>65.460863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Local Delta  Global Delta  Best's set size (%)  \\\n",
       "P. Method Param                                                   \n",
       "dirY      0.5        0.07976       0.06544                52.32   \n",
       "          0.75       0.09080       0.05448                59.84   \n",
       "          1          0.09776       0.04824                54.88   \n",
       "          10         0.10888       0.00472                79.20   \n",
       "powN      0.1        0.06560       0.00316                46.48   \n",
       "          0.25       0.04836       0.00144                57.44   \n",
       "          0.5        0.03844       0.00100                64.32   \n",
       "          0.75       0.03460       0.00160                67.52   \n",
       "          1          0.03332       0.00108                65.44   \n",
       "\n",
       "                 Best's dataset size (%)  \n",
       "P. Method Param                           \n",
       "dirY      0.5                  52.320000  \n",
       "          0.75                 59.840000  \n",
       "          1                    54.880000  \n",
       "          10                   79.200000  \n",
       "powN      0.1                  84.210697  \n",
       "          0.25                 80.066621  \n",
       "          0.5                  75.347766  \n",
       "          0.75                 69.877587  \n",
       "          1                    65.460863  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_param=synth_table.groupby(['P. Method','Param'])[\n",
    "    ['Local Delta','Global Delta','Best\\'s set size (%)','Best\\'s dataset size (%)']\n",
    "]\n",
    "# Used to make Table 3.4\n",
    "by_param.mean().to_csv('tmp/data_experiments/synth_by_param_mean.csv')\n",
    "by_param.std().to_csv('tmp/data_experiments/synth_by_param_std.csv')\n",
    "by_param.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
